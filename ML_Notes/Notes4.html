<div id="article_content" class="article_content clearfix">
        <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/ck_htmledit_views-1a85854398.css">
                <div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p>
<div class="toc">
 <h3><a name="t0"></a>文章目录</h3>
 <ul><li><a href="#CNN_1" target="_self">一、卷积神经网络（CNN）</a></li><li><ul><li><a href="#11_Image_Classification_3" target="_self">1.1 Image Classification</a></li><li><ul><li><a href="#111_CNN_9" target="_self">1.1.1 CNN的第一种解释</a></li><li><a href="#112CNN_28" target="_self">1.1.2CNN的第二种解释</a></li><li><a href="#113__33" target="_self">1.1.3 两种方法的比较</a></li></ul>
   </li><li><a href="#12_pooling_35" target="_self">1.2 池化层（pooling）</a></li></ul>
  </li><li><a href="#_43" target="_self">二、结语</a></li></ul>
</div>
<p></p> 
<h1><a name="t1"></a><a id="CNN_1"></a>一、卷积神经网络（CNN）</h1> 
<p>CNN是专门被设计在影像上的，如图像分类</p> 
<h2><a name="t2"></a><a id="11_Image_Classification_3"></a>1.1 Image Classification</h2> 
<p>当我们对图像进行分类的时候，图像的大小可能是不一样的，所以我们把他们的形状变得一样再丢尽=进网络中进行训练。而对图像的表示方法，我们可以用独热向量（One-Hat-vector）表示:[0 0 0 0 0 0 1 0 0 0 …]向量的长度取决于图像种类的数量，最终结果经过softmax后变成概率分布，概率最大为最终结果。<br> 对于一张彩色图片，有三个通道（channels），我们可以把他看成由一个三维的Tensor组成，而当图像输入时，我们常常是将tensor拉直直接作为网络的输入：<br> <img src="https://img-blog.csdnimg.cn/ab5121617c3842de9ce4bea012147c51.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5q275Zyo5rex5bqm5a2m5Lmg,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 上面可以简单计算输入一共有100 * 100 * 3个，当是进入全连接网络是，因为每一个神经元与每一个输入都要有一个weight，假如第一层有1000个神经元，那么第一层总共需要1000 * 100 * 100 * 3个权重参数，数量十分具大！<img src="https://img-blog.csdnimg.cn/d2a11817a51249b88dd8dbb81a50fd2f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5q275Zyo5rex5bqm5a2m5Lmg,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 参数越多，虽然会使网络的弹性越大，但也可能会导致过拟合，影响预测结果。我们可以看出全连接网络并不是很适合做影片识别，因为他每一个神经元都将图片的全部点都看过一遍，存在大量的重合部分，对于图片而言，其实他是有某一部分就能决定这张图片的种类，所以很多神经元是多余的。<img src="https://img-blog.csdnimg.cn/3406de1edf804ad38431836f9d2518f2.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5q275Zyo5rex5bqm5a2m5Lmg,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p> 
<h3><a name="t3"></a><a id="111_CNN_9"></a>1.1.1 CNN的第一种解释</h3> 
<p>我们让一个神经元只看图片的一部分特征<br> <img src="https://img-blog.csdnimg.cn/3232147ff8fa42d6822dde49d5161319.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5q275Zyo5rex5bqm5a2m5Lmg,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 如上述图片的神经元只看3 * 3 * 3部分的特征，而这个区域叫做Receptive field（感受野），而这样的话神经元只需要3 * 3 * 3个weight参数，参数量减少很多。而Receptive field是可以重叠的<img src="https://img-blog.csdnimg.cn/d41fe699254449fb9fed9e1329841929.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5q275Zyo5rex5bqm5a2m5Lmg,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 因为图片的所有调整我们都会看，所以只要关心感受野的高和宽进行，深度不用理，我们一般用kernel size（卷积核）去表示感受野，且我们是有一组的神经元去关照这个感受野的<img src="https://img-blog.csdnimg.cn/5be4328adaf64dbb8ce1ed6d8aa32d3f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5q275Zyo5rex5bqm5a2m5Lmg,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 看完这个范围之后，我们要移动到下一个范围，但要移动多少呢，这由stride参数决定，一般来说取1，2<img src="https://img-blog.csdnimg.cn/6768ea2c29874ff4acf0d93f6487ec05.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5q275Zyo5rex5bqm5a2m5Lmg,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 当我们继续移动使，到后面就会遇到一个问题，就是感受野超过了图像的范围，我们会用padding的补值方法，以此下去，在看完横向之后，又会继续往垂直方向看<img src="https://img-blog.csdnimg.cn/c1db27bf38cf45b58466d8187c3a3b05.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5q275Zyo5rex5bqm5a2m5Lmg,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 补充：虽然笔记做得是理论知识的记录，但也要回到操作上，卷积神经网络的方法是<br> nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)<br> in_channels表示输入通道<br> out_channels表示输出通道<br> kernel_size表示卷积核大小，用f表示<br> stride表示步长，用s表示<br> padding表示填充的数目，注意一般填充时是整一个图片周围的填充，而不是某一维的填充，大小用p表示<br> 首先做实验我们知道当padding为零的时候，图像在经过卷积神经网络之后是变小的，而如果我们能使padding的值合适，图像的大小是不变的。这就涉及到p的计算和输出图像维度n的计算，如以下公式：<br> p = (f - 1) // 2<br> n’ = [(n + 2p - f) // s] + 1<br> 接下来再看看参数共享问题，我们知道感受野是由一系列的神经元来控制的，但也有一个问题是，因为生物是有共性的，比如说鸟都有嘴，如果我们在找每一张图片的鸟嘴时，都要一组不同的参数，那这样参数太多了，因为机器是在做着相同的事情，所以我们可以使在特定感受野不同的神经元的weight参数是一样的<img src="https://img-blog.csdnimg.cn/aa45f9c435cf4f61817807deca29c4e9.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5q275Zyo5rex5bqm5a2m5Lmg,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 因为输入不一样，所以他们的输出自然也不一样。CNN的第一种解释可以这样简单的描述<img src="https://img-blog.csdnimg.cn/abd9e24a348f4201ac70e825227e5582.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5q275Zyo5rex5bqm5a2m5Lmg,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p> 
<h3><a name="t4"></a><a id="112CNN_28"></a>1.1.2CNN的第二种解释</h3> 
<p>对于卷积神经网络，就是按照卷积核的大小在图像中抓取部分的图案然后进行分析<img src="https://img-blog.csdnimg.cn/e1d4404e6da441eeafe6aba2e0046a0d.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5q275Zyo5rex5bqm5a2m5Lmg,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 那又是如何抓取，首先卷积核是一个个的tensor，而他的数值是通过学习而来的，然后放到图像上，与对应的值做内积得到一个值<img src="https://img-blog.csdnimg.cn/cad90f5bb4f64e2dbba6b976ab31f8b6.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5q275Zyo5rex5bqm5a2m5Lmg,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 然后卷积核会按照stride的长度往左右上下移动，全部做内积，最终得到一个新的图像Tensor，最后再用每一个卷积核做相同的过程，得到一个特征图<img src="https://img-blog.csdnimg.cn/50a0b092ff6d40babc8aff138df49f3a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5q275Zyo5rex5bqm5a2m5Lmg,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 我们可以得到的特征图看作一张新的图片，假如说有64个卷积核，那么新图片就有64个通道。我们用卷积核扫过整张图片的过程就是卷积（Convolution），对应的层叫做卷积层</p> 
<h3><a name="t5"></a><a id="113__33"></a>1.1.3 两种方法的比较</h3> 
<p><img src="https://img-blog.csdnimg.cn/4f208337858a4220891683e6e210c0ea.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5q275Zyo5rex5bqm5a2m5Lmg,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p> 
<h2><a name="t6"></a><a id="12_pooling_35"></a>1.2 池化层（pooling）</h2> 
<p>当我们把一张大的图片缩小，但是不会影响图片的性质，这就是pooling所能做的事情pooling中没有参数，他的行为是固定好的，类似激活函数，破零有许多种如：Min pooling、Mean pooling、Max poolingd等，这里记录Maxpooling<br> 我们前面说过当经过卷积之后会产生新的tensor，我们再把得到的tensor分成分成许多的组<img src="https://img-blog.csdnimg.cn/730d75331e7c46d8983f8da966ae5559.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5q275Zyo5rex5bqm5a2m5Lmg,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> Max pooling做的事情就是取出最大值，然后由这些值组成新的tensor，这样就可以达到缩小图片的效果<br> <img src="https://img-blog.csdnimg.cn/050e7c7d2d9e4ff4b97084b927457304.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5q275Zyo5rex5bqm5a2m5Lmg,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 我们一般在做完卷积之后通常会搭配pooling，或者说我们一般会交替使用convolution和pooling<br> <img src="https://img-blog.csdnimg.cn/7c02427549fe40f4995ecc1fe35f073a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5q275Zyo5rex5bqm5a2m5Lmg,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 对于整个的CNN神经网络结果大概是下面这样，同时，在昨晚做完卷积之后，我们会加上几层的全连接层，经过softmax得到最终结果<img src="https://img-blog.csdnimg.cn/540f8f95ba274262b568e87dc2db78f6.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5q275Zyo5rex5bqm5a2m5Lmg,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p> 
<h1><a name="t7"></a><a id="_43"></a>二、结语</h1> 
<p>本来本期的学习笔记应该要从CNN记录到自注意力机制（self-attention），但是在学习后者过程中对其背后的原理没能彻底理解，所以在此并没有记录。日后等钻研明白之后再过来补充完整，哈哈，偷懒。学习笔记中定有许多错误之处，还望指教，共勉！</p>
                </div><div data-report-view="{&quot;mod&quot;:&quot;1585297308_001&quot;,&quot;spm&quot;:&quot;1001.2101.3001.6548&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_53598445/article/details/120462676&quot;,&quot;extend1&quot;:&quot;pc&quot;,&quot;ab&quot;:&quot;new&quot;}"><div></div></div>
                <link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-d7a94ec6ab.css" rel="stylesheet">
                <link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-49037e4d27.css" rel="stylesheet">
        </div>