<div id="article_content" class="article_content clearfix">
        <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/ck_htmledit_views-1a85854398.css">
                <div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p>
<div class="toc">
 <h3><a name="t0"></a>生成式对抗网络</h3>
 <ul><li><a href="#_1" target="_self">一、基本概念介绍</a></li><li><ul><li><a href="#Generator_5" target="_self">Generator</a></li><li><a href="#Discriminator_9" target="_self">Discriminator</a></li><li><a href="#Algorithm_17" target="_self">Algorithm</a></li></ul>
  </li><li><a href="#_21" target="_self">二、理论介绍</a></li><li><a href="#_33" target="_self">三、生成器效能评估与条件生成</a></li><li><ul><li><a href="#Possible_Solution_39" target="_self">Possible Solution</a></li><li><a href="#Quality_of_Image_41" target="_self">Quality of Image</a></li><li><a href="#Conditional_Generator_47" target="_self">Conditional Generator</a></li></ul>
  </li><li><a href="#Cycle_GAN_57" target="_self">四、Cycle GAN</a></li><li><a href="#_66" target="_self">五、结语</a></li></ul>
</div>
<p></p> 
<h1><a name="t1"></a><a id="_1"></a>一、基本概念介绍</h1> 
<p>在GAN之前我们学到的架构都是我们会给他一个x然后他经过神经网络之后输出一个y<br> <img src="https://img-blog.csdnimg.cn/8bafd89855134e728e442f4d55b375b4.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_11,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 现在我们要把Network当作Generator来用，让网络自己产生一些东西，这样网络的输入不再是单单的x，还要加上一个Simple Distribution，然后输出是一个复杂的概率分布，我们就把这样的网络叫做Generator<img src="https://img-blog.csdnimg.cn/b2d9e2e03aa34e5dbaf39a81b3af6f80.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_14,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p> 
<h2><a name="t2"></a><a id="Generator_5"></a>Generator</h2> 
<p>例子：让机器生成动漫人物脸，这里做的是Unconditional generation，就是在网络的输入当中将x去掉只剩下Z做输入，Z一般来说是一个低维的向量，丢到generator中输出<br> <img src="https://img-blog.csdnimg.cn/2dd7770245324ba4ab9eccb56063bc87.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_14,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 图片本身就是十分长的向量，所以generator的输出就是一排向量。</p> 
<h2><a name="t3"></a><a id="Discriminator_9"></a>Discriminator</h2> 
<p>Discriminator本身也是一个network、函数，接受图片的输入，输出是一个scalar，这个值越大，说明Generator生成的图片的真实度越大。Discriminator的架构是我们自行决定的，如果想处理图像问题，那架构可能更多地使用CNN来组成<br> <img src="https://img-blog.csdnimg.cn/e757dcc686ff423a949933fb79751802.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_16,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 为什么要有Discriminator，其实这可以用进化理论来解释，也就是物竞天择，因为对GAN来说，我是要生成一些东西，这部分由Generator来完成。Generator开始时地参数是随机的，所以生成的东西是很随意的，比如上面的例子来说，Generator生成的二次元人物可能是没有眼睛的，这样的话当图片输入到Discriminator时，Discriminator给的分数很低，不让你通过，那Generator就会根据这一点来更新自己的参数，以生成更像二次元人物的图片，调整的方向就是要骗过discriminator<br> <img src="https://img-blog.csdnimg.cn/02b827a12fa140f29530b893df35ec3d.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_10,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 但是，Discriminator也是会进化的，第一次的时候可能检查的是眼睛，现在可能检查嘴巴等其他特征来判断Generator生成的图片是不是二次元人物<br> <img src="https://img-blog.csdnimg.cn/06afe3770e0247379e228c9033e8df89.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_15,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 由此看出，Discriminator和Generator是存在对抗关系的。</p> 
<h2><a name="t4"></a><a id="Algorithm_17"></a>Algorithm</h2> 
<p>首先，初始化G(Generator)和D(Discriminator)的参数。再者，训练G，在网络爬到真正的二次元人物，然后比较G产生的图片与真正的类别，不断更新参数<img src="https://img-blog.csdnimg.cn/509c0a721f6f44ff8f239c1a81c3c15e.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_14,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 最后因为G产生的图片是要骗过D的，所以D就会增加判断G生成的图片的特征来给图片打分，根据分数是使G的参数更新<img src="https://img-blog.csdnimg.cn/3ac4f0de72ad4fe583fc5901cf65f449.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_15,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述">当D打的分数比较高时，G就可能骗过D，输出图片。我们可以把G和D看成一个整体的网络，但是参数更新时我们不会更新D部分的参数<img src="https://img-blog.csdnimg.cn/6df9f61b8d05442ea532d705928b7739.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_15,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 两个步骤合起来之后就是下面这样，两个网络是轮流进行训练的<img src="https://img-blog.csdnimg.cn/83ad03d519214a07b7c4d38c9ca4a04c.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_16,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p> 
<h1><a name="t5"></a><a id="_21"></a>二、理论介绍</h1> 
<p>我们在训练的时候是要定义Loss函数，然后不断去使他最小化，而在GAN中同样的，我们期待我们G生成的东西与真实的东西Pdata越接近越好<br> <img src="https://img-blog.csdnimg.cn/95b304f07b16479e9517ac44c616aa6a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_15,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 式子可以写成这样：<br> <img src="https://img-blog.csdnimg.cn/ae7b0f231eae4d22b2ea560089413f6e.png" alt="在这里插入图片描述"><br> Divergence表示G生成的与真实的东西的距离，所以我们要找到一组参数使得Divergence越来越小，但是不知道怎么算这个距离。以此GAN是用小数量的样本进行计算，分别从真实图库和G产生的图片Sample一部分出来后就可以计算<img src="https://img-blog.csdnimg.cn/508be2b91fea458081e2bb39a28d24e4.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_16,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 根据这些数据可以做训练，将PG丢给D判断，给出分数高低，同时也可以把这个过程当成optimization。找到使D最大的参数，式子由下面所示，对于最下面的式子，我们希望如果Y是从Pdata出来的，则越大越好，如果是从PG中Sample出来的，则希望他越小越好<br> <img src="https://img-blog.csdnimg.cn/fa2ab43514964c45911b8f0584fd093e.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_15,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 因为我们是将两种数据混合在一起的，所以对D而言就是在做一个二元分类问题，当Pdata和PG之间的距离很小时，他们混合的程度越大，对于D来说越不容易做分类，就会给出很高的分数，相反则会给很低的分数<br> <img src="https://img-blog.csdnimg.cn/067cbd57ff094f06988a627afff89778.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_16,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 所以我们从最开始计算divergence的最小值转化成了计算D*的最大值，且二者是相关的，则可以这样代替<br> <img src="https://img-blog.csdnimg.cn/72ac628886e440a78f071a5d711b378a.png" alt="在这里插入图片描述"></p> 
<h1><a name="t6"></a><a id="_33"></a>三、生成器效能评估与条件生成</h1> 
<p>GAN是十分难train的，Generator和Discriminator是相互抵抗、共同成长的，只要其中一者停止训练，那另一者也会跟着停止<br> <img src="https://img-blog.csdnimg.cn/d70b442712f74ce3ac5d00a02b6191c7.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_15,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 对GAN来说生成一段文字是最难的，对于GAN做Sequence-to-Sequence而言，Generator就是Decoder，然后丢给Discriminator，然后D打分是不是真正的句子，那G就是根据分数进行参数调整，以骗过D。<br> <img src="https://img-blog.csdnimg.cn/4f7ddbec38154e6aa1317d43ddef41b7.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_16,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 但事实是，当你在做微分的时候，Decoder会有微小的变化，取max之后，无法改变Decoder的输出，也无法提高D打的分数。这里就可以使用reinforcement Learning进行训练，但十分困难。</p> 
<h2><a name="t7"></a><a id="Possible_Solution_39"></a>Possible Solution</h2> 
<p>可以尝试supervised的方法进行训练，就是拿真正的图片当作标签给G当参考，一直训练下去<img src="https://img-blog.csdnimg.cn/22003bab3656429d8df8d8a15070c5b0.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_15,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p> 
<h2><a name="t8"></a><a id="Quality_of_Image_41"></a>Quality of Image</h2> 
<p>当G产生的图片时，可以把图片丢到影像分类系统中进行判断，最终输出一个概率分图，当分布十分集中时，那G产生的图片可能就是真正的图片<br> <img src="https://img-blog.csdnimg.cn/5f4d07f0e106420489e3b38024a002ea.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_15,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 但这种方法会被Mode Collagse问题骗过，这种情况下，G产生的图片只有那几张图片，这样D就一直认为是真的图片。因此我们要判断图片的多样性够不够，有下面方法，就是判断图片种类加权平均之后概率分布是否平均<br> <img src="https://img-blog.csdnimg.cn/1ed41a8a52304193b0c4dcddecaeec64.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_16,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 但是在评估G的时候，还需要判断其产生的东西是否是我们想要的。因此需要更多的评估方法。</p> 
<h2><a name="t9"></a><a id="Conditional_Generator_47"></a>Conditional Generator</h2> 
<p>我们之前的G的产生都是随机的，如果我们想要控制G的输出，就给G多一些限制性的输入<img src="https://img-blog.csdnimg.cn/ef34d9fb904d453f8deb8f16b14e6eff.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_15,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 比如说G输入的限制是红眼睛，那其输出的图片中均是红眼睛<br> <img src="https://img-blog.csdnimg.cn/c0349ccf832a4f85a7877399ea09b3e4.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_15,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 接下来就要做Condition GAN，之前的GAN模型如下<br> <img src="https://img-blog.csdnimg.cn/077389e7a0934d3c8994c07e9fa51542.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_16,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 但是这样的训练的话，D并没有考虑到输入限制问题，这样的话G只要产生清晰的图片就可以骗过D，根本无关是否是红眼睛，所以D还要根据限制条件来给分此过程中还需给一些错误的训练数据<br> <img src="https://img-blog.csdnimg.cn/181455a7db7e4275bf14d56c4453423b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_16,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> Conditional GAN除了输入语音产生图片之外，还可以输入图像产生图像<br> <img src="https://img-blog.csdnimg.cn/1aa815d8764d4e0899480dbcedb03bb1.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_16,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p> 
<h1><a name="t10"></a><a id="Cycle_GAN_57"></a>四、Cycle GAN</h1> 
<p>GAN话可以用在Unsupervised Leaning上。在supervised Learning上，当我们训练一个网络的时候输入一个x，输出一个y，训练资料一般成对的，未成对的资料叫做unpaired资料<img src="https://img-blog.csdnimg.cn/7e26cc2206f44c0385367abe441f2fe3.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_15,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 而对影像风格转化的训练中是完全没有成对资料的，对于G而言，我们要训练一个输入为X-domain的图片，输出Y-domain的图片<img src="https://img-blog.csdnimg.cn/9353835129af446ea477e655023fe01a.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_16,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 按照之前的方法，我们可以直接在X-domain图片中sample一部分出来，丢到G然后输出就可以了，但是的话这样是不够的，因为这样的话没有任何的限制，这样的话G的输出可以跟输入图片没有任何关系，这一点跟Conditional GAN很像<img src="https://img-blog.csdnimg.cn/ef2c763aa86c4887aa7ffe3e5fc5d8ea.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_15,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 所以就用了Cycle GAN，里面用了两个G，第一个G输入X-domain的图片，输出一张Y-domain图片，第二个G是将第一个G产生的图片还原回最开始输入的X-domain图片，<img src="https://img-blog.csdnimg.cn/9d30f81ec4c34d83bc81ac3276be1ac5.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_16,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> D就会根据两张X-domain图片的相似程度进行打分，越像则分数越高。话第一个G的输出可能产生跟输入完全不同的图，这样的话第二个G就不会产生跟最开始输入的图片相关的图，<img src="https://img-blog.csdnimg.cn/3f8178a6bbde4892990fd10a9b4fb5de.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_16,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 所以为第二个G的输出能够还原图片，所以就会强制第一个G的输出跟输入的X-domain图片是相关联的。相互的Cycle GAN也可以是相向的的，也可以用Y-domain图片来做<br> <img src="https://img-blog.csdnimg.cn/381de9e8cb9a478387f40a00153fea94.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_16,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 二者合起来就是Cycle GAN。</p> 
<h1><a name="t11"></a><a id="_66"></a>五、结语</h1> 
<p>此次读书笔记是本人学习机器学习的第六篇，如有不足之处还请指出。</p>
                </div><div data-report-view="{&quot;mod&quot;:&quot;1585297308_001&quot;,&quot;spm&quot;:&quot;1001.2101.3001.6548&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_53598445/article/details/120813760&quot;,&quot;extend1&quot;:&quot;pc&quot;,&quot;ab&quot;:&quot;new&quot;}"><div></div></div>
                <link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-d7a94ec6ab.css" rel="stylesheet">
                <link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-49037e4d27.css" rel="stylesheet">
        </div>