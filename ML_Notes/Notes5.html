<div id="article_content" class="article_content clearfix">
        <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/ck_htmledit_views-1a85854398.css">
                <div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p>
<div class="toc">
 <h3><a name="t0"></a>文章目录</h3>
 <ul><li><a href="#Transformer_1" target="_self">（一）Transformer</a></li><li><ul><li><a href="#Encoder_10" target="_self">Encoder</a></li><li><a href="#Decoder_15" target="_self">Decoder</a></li><li><ul><li><a href="#AutoregressiveAT_17" target="_self">Autoregressive（AT）</a></li><li><a href="#NonautoregressiveNAT_28" target="_self">Non-autoregressive（NAT）</a></li></ul>
   </li><li><a href="#EncoderDecoder_30" target="_self">Encoder和Decoder之间的桥梁</a></li><li><a href="#_34" target="_self">训练</a></li></ul>
  </li><li><a href="#_39" target="_self">（二）结语</a></li></ul>
</div>
<p></p> 
<h1><a name="t1"></a><a id="Transformer_1"></a>（一）Transformer</h1> 
<p>Transformer是Sequence-toSequence（Seq2Seq）的一个模型，我们之前在作一些实验的时候，当我们输入一个Sequence时，我们的输出也会是一个Sequence，而输入和输出结果的长度是一样的，当我们不知道输出结果是有多长时，我们便要机器自己决定要输出多长，这就会用到Seq2Seq，特别是在语音辨识及机器翻译中。<br> <img src="https://img-blog.csdnimg.cn/8420b887f89d4bfbbc3a69b3cabf76c7.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 一般的Seq2Seq模型是由Encoder和Decoder组成，Encoder接受外界的输入，然后把输出的结果丢给Decoder，再由Decoder决定要输出的Sequence的大小<img src="https://img-blog.csdnimg.cn/0c7feb608f9d448081eed81a79aaff31.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_12,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> Seq2seq最早在14年的时候就有了，那时是长的很眉清目秀，后面就变得一言难尽了<br> <img src="https://img-blog.csdnimg.cn/2df919b70adc4d648668668bb89c45b8.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> <img src="https://img-blog.csdnimg.cn/6fd8e35d462b41578578a96462ed6cdc.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_11,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p> 
<h2><a name="t2"></a><a id="Encoder_10"></a>Encoder</h2> 
<p>Encoder要做的事情就是输入一排向量然后输出一排长度相同向量，这个用RNN或者CNN都能做得到，Encoder用的是self-attention（在我第四篇笔记中有记录到，欢迎大家指正）<img src="https://img-blog.csdnimg.cn/799b3825287f42f3bf6fbc985faf306d.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 现在的Encoder会被分成很多个block，每一个block先做一个self-attention，接受一排向量的输入，考虑全部的资讯，然后输出一排向量，再把结果丢到全连接层再输出一排向量，这就是每一个block的输出，<img src="https://img-blog.csdnimg.cn/b7b21b5cc1414980aa9437ef22899360.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 实际上原来的transformer中，block做的事情更加复杂，在经过self-attention得到一排向量之后，并不会直接丢给全连接层，而是将输入加进来得到新的向量，当成新的output，这种架构叫做residual connection，再将得到的新output做layer normalization（不需要考虑batch），layer normalization在同一个feature中计算不同维度的mean，standard，用公式x’i = （xi - mean）/ std归一化，得到要输入到全连接层的结果，<img src="https://img-blog.csdnimg.cn/683d780331e142f7a415edf6d24b9d63.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 同样的，全连接层里面也有residual connection的架构和normalization，然后才得到一个block的输出</p> 
<h2><a name="t3"></a><a id="Decoder_15"></a>Decoder</h2> 
<p>这里记录两种常用的Decoder</p> 
<h3><a name="t4"></a><a id="AutoregressiveAT_17"></a>Autoregressive（AT）</h3> 
<p>语音辨识例子：<br> 给Encoder吃入”机器学习“的一段语音，Encoder会输出四排向量；对于Decoder来说，他的输入就是encoder的输出，首先Decoder有一个代表开始的符号BEGIN，缩写是BOS<img src="https://img-blog.csdnimg.cn/715b8a0576d1412eaadd11ec7880deed.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_14,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> Decoder接受的每一个输入都可以用One-hot-vector来表示，然后Decoder会吐出一排向量，大小是一个字典的长度，比如说做的是中文的语音辨识，中文大概有三四千常用字，所以Decoder吐出向量的长度是三四千。在Decoder中，结果还会经过softmax，最终会给每一个文字一个分数，分数最高的为所需结果<br> <img src="https://img-blog.csdnimg.cn/1404668e0ef648f2b3007db4ac9dfc4c.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 同样的，第一个的输出再作为第二次的输入，进行同样过程。<img src="https://img-blog.csdnimg.cn/ce101b78da504ed9b826fd5a90a678cb.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 我们能够发现Decoder的输出会被当成下一次的输入，这也会导致一个问题，就是当Deocder在某一次的输出错误的话就可能会导致后面的结果全部错误。接下来看一下Decoder的内层结果<img src="https://img-blog.csdnimg.cn/9f95166088654f9e86bd18c9aa3bacca.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_19,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 可以看出，Decoder除了中间部分和结果处的softmax之外，跟Encoder是差不多的。还有一个地方就是在Decoder里面self-attention变成了Masked self-attention，Masked其实是对self-attention的一个限制，就是让网络由可以考虑全部的资讯变成只能考虑左边的资讯<img src="https://img-blog.csdnimg.cn/1c3451b3285c4f30a74e92b7dc2f184c.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 例如下面，在输出b2时，只用第二个query和第一、二个的key相乘，而不考虑key3和key4<br> <img src="https://img-blog.csdnimg.cn/0977980c78be4cee969f63d12c61ddbd.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 因为在Decoder中，输入不是一次性全部输入的，他是先有a1，再有a2，a3，a4，所以当你要输出b2时，是没有a3，a4的。开始的时候我们讲到Decoder是要有一个开始符号的，那类似的，Decoder也有结束的符号end<img src="https://img-blog.csdnimg.cn/175fce77a9314ab59d101724efa51106.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p> 
<h3><a name="t5"></a><a id="NonautoregressiveNAT_28"></a>Non-autoregressive（NAT）</h3> 
<p>对于NAT Decoder，他是一次性吃一整排的向量，然后直接生成一个 句子，就很直接，<img src="https://img-blog.csdnimg.cn/c49f93cf2db7409684fb4887c7a4dc90.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_10,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p> 
<h2><a name="t6"></a><a id="EncoderDecoder_30"></a>Encoder和Decoder之间的桥梁</h2> 
<p>Decoder通过产生一个query，到Encoder中抽取资讯，然后当作Decoder中的全连接层的输入，这个过程叫做Cross attention<br> <img src="https://img-blog.csdnimg.cn/a29c634964fb4d99a10f88f51e34fd40.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> Decoder的输入接下来的处理是一样的。</p> 
<h2><a name="t7"></a><a id="_34"></a>训练</h2> 
<p>我们还是用语音辨识的例子，假如输入的是”机器学习“，每一个字用一个独热向量表示，但我们经过Decoder得到第一个输出，这个输出是一个概率分布，我们会用”机“对应的独热向量跟输出进行cross entropy的计算<img src="https://img-blog.csdnimg.cn/124fca4530af4c51af1a41c188054dd7.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 每一个输出都有一个cross entropy，而我们就要使总cross entropy loss越小越好，但是要注意的是，我们还要输出end（结束）向量<img src="https://img-blog.csdnimg.cn/bb1ad953d6d34a37af836c9fd9bc3c6f.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 可以观察到我们在训练的时候，Decoder的输入都是正确的，这个叫Teacher Forcing：using the ground truth as input。但我们在测试时看的是自己的输入，可能有时候的输出是错误的，比如说将“器”输出成“气”，就可能导致后面全部错，所以我们在训练过程中需要给model加一些错误的信息让他去训练<img src="https://img-blog.csdnimg.cn/a982959eed6d4ef1b9b81822e6cdf7f8.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5oiR5piv6I-c6bih5L2G5oiR6L-Y6KaB6K-0,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"><br> 这个叫做Scheduled Sampling。</p> 
<h1><a name="t8"></a><a id="_39"></a>（二）结语</h1> 
<p>以上是我本人学习机器学习的学习笔记的第五篇，有错误的地方还望指出，共勉！</p>
                </div><div data-report-view="{&quot;mod&quot;:&quot;1585297308_001&quot;,&quot;spm&quot;:&quot;1001.2101.3001.6548&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_53598445/article/details/120659956&quot;,&quot;extend1&quot;:&quot;pc&quot;,&quot;ab&quot;:&quot;new&quot;}"><div></div></div>
                <link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-d7a94ec6ab.css" rel="stylesheet">
                <link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-49037e4d27.css" rel="stylesheet">
        </div>