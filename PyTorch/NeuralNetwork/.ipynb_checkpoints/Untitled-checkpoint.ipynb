{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a564978b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 8, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super(Net, self).__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(1, 6, 3, 1, 1),\n",
    "                                nn.BatchNorm2d(6),\n",
    "                                nn.ReLU(),\n",
    "                                nn.MaxPool2d(2, 2, 0),\n",
    "                                \n",
    "                                nn.Conv2d(6, 12, 3, 1, 1),\n",
    "                                nn.BatchNorm2d(12),\n",
    "                                nn.ReLU(),\n",
    "                                nn.MaxPool2d(2, 2, 0),\n",
    "                                \n",
    "                                nn.Linear(8, 4), \n",
    "                                nn.Linear(4, 2))\n",
    "    def forward(self, x) :\n",
    "        return self.net(x)\n",
    "net = Net()\n",
    "# print(net)\n",
    "\n",
    "# para = list(net.parameters())\n",
    "# print(para)\n",
    "\n",
    "input = torch.randn(1, 1, 32, 32)#第一个1表示batch，第二个1表示通道数\n",
    "output = net(input)\n",
    "print(output.size())\n",
    "\n",
    "net.zero_grad()\n",
    "output.backward(torch.randn(1, 12, 8, 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a5e0270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "\tIn Model: input size torch.Size([30, 5]) output size torch.Size([30, 2])\n",
      "Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n",
      "30\n",
      "\tIn Model: input size torch.Size([30, 5]) output size torch.Size([30, 2])\n",
      "Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n",
      "30\n",
      "\tIn Model: input size torch.Size([30, 5]) output size torch.Size([30, 2])\n",
      "Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n",
      "10\n",
      "\tIn Model: input size torch.Size([10, 5]) output size torch.Size([10, 2])\n",
      "Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "input_size = 5\n",
    "output_size = 2\n",
    "batch_size = 30\n",
    "data_size = 100\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class RandomDataSet(Dataset) :\n",
    "    def __init__(self, size, length) :\n",
    "        self.len = length\n",
    "        self.data = torch.randn(length, size)\n",
    "    def __getitem__(self, item) :\n",
    "        return self.data[item]\n",
    "    def __len__(self) :\n",
    "        return self.len\n",
    "    \n",
    "dataset = RandomDataSet(input_size, data_size) \n",
    "dataloader = DataLoader(dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "class Model(nn.Module) :\n",
    "    def __init__(self, input_size, output_size) :\n",
    "        super(Model, self).__init__()\n",
    "        self.net = nn.Linear(input_size, output_size)\n",
    "    def forward(self, x) :\n",
    "        output = self.net(x) \n",
    "        print(\"\\tIn Model: input size\", input.size(),\n",
    "             \"output size\", output.size())\n",
    "        return output\n",
    "    \n",
    "model = Model(input_size, output_size)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "    model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "for data in dataloader:\n",
    "    input = data.to(device)\n",
    "    output = model(input)\n",
    "    print(\"Outside: input size\", input.size(),\n",
    "     \"output_size\", output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e2a99b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "0 torch.Size([4, 3, 244, 244]) torch.Size([4, 68, 2])\n",
      "1 torch.Size([4, 3, 244, 244]) torch.Size([4, 68, 2])\n",
      "2 torch.Size([4, 3, 244, 244]) torch.Size([4, 68, 2])\n",
      "3 torch.Size([4, 3, 244, 244]) torch.Size([4, 68, 2])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd #用于更容易地进行csv解析\n",
    "from skimage import io, transform #用于图像的IO和变换\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "%matplotlib\n",
    "# 忽略警告\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.ion() # interactive mode\n",
    "\n",
    "landmarks_frame = pd.read_csv(r'faces/face_landmarks.csv')\n",
    "\n",
    "# n = 65\n",
    "# img_name = landmarks_frame.iloc[n, 0]\n",
    "# # print(img_name)\n",
    "# landmarks = landmarks_frame.iloc[n, 1 : ]\n",
    "# landmarks = torch.tensor(landmarks.values.astype('float'))\n",
    "# landmarks = landmarks.reshape(-1, 2)\n",
    "# print(landmarks.size())\n",
    "\n",
    "def show_landmarks(image, landmarks) :\n",
    "    plt.imshow(image)\n",
    "    plt.scatter(landmarks[ : , 0], landmarks[ : , 1], s = 10, marker = '.', c = 'r')\n",
    "    plt.pause(0.001)\n",
    "\n",
    "# img = io.imread(os.path.join('faces/', img_name))\n",
    "# show_landmarks(img, landmarks)\n",
    "# plt.show()\n",
    "\n",
    "#自定义数据集\n",
    "class FaceLandmarksDataSet(Dataset) :\n",
    "    def __init__(self, csv_file, root_dir, transform = None) :\n",
    "        self.landmarks_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    def __getitem__(self, item) :\n",
    "        img_name = os.path.join(self.root_dir, self.landmarks_frame.iloc[item, 0])\n",
    "        image = io.imread(img_name)\n",
    "        landmarks = self.landmarks_frame.iloc[item, 1 : ]\n",
    "        landmarks = torch.tensor(landmarks.values.astype('float'))\n",
    "        landmarks = landmarks.reshape(-1, 2)\n",
    "        sample = {'image' : image, 'landmarks' : landmarks}\n",
    "        \n",
    "        if self.transform :\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    def __len__(self) :\n",
    "        return len(self.landmarks_frame)\n",
    "face_dataset = FaceLandmarksDataSet(csv_file = r'faces/face_landmarks.csv', root_dir = r'faces/')\n",
    "#可视化\n",
    "# for i in range(len(face_dataset)) :\n",
    "#     sample = face_dataset[i]\n",
    "#     print(i, sample['image'].shape, sample['landmarks'].shape)\n",
    "#     h, w = sample['image'].shape[ : 2]\n",
    "#     print(h, w)\n",
    "#     ax = plt.subplot(1, 4, i + 1)\n",
    "#     plt.tight_layout()#tight_layout会自动调整子图参数，使之填充整个图像区域。这是个实验特性，可能在一些情况下不工作。它仅仅检查坐标轴标签、刻度标签以及标题的部分\n",
    "#     ax.set_title('Sample #{}'.format(i))\n",
    "#     ax.axis('off')\n",
    "#     show_landmarks(sample['image'], sample['landmarks'])\n",
    "#     if i == 3:\n",
    "#         plt.show()\n",
    "#         break\n",
    "\n",
    "#将样本中的图像重新缩放到给定大小。\n",
    "# output_size（tuple或int）：所需的输出大小。 如果是元组，则输出为\n",
    "# 与output_size匹配。 如果是int，则匹配较小的图像边缘到output_size保持纵横比相同\n",
    "class Rescale() :\n",
    "    def __init__(self, output_size) :\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "        \n",
    "    def __call__(self, sample) :\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "        h, w = image.shape[ : 2]\n",
    "        \n",
    "        if isinstance(self.output_size, int) :\n",
    "            if h > w :\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else :\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else :\n",
    "            new_h, new_w = self.output_size\n",
    "            \n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "        landmarks = landmarks * torch.tensor([new_w / w, new_h / h])#对landmarks的每一行两元素分别乘该行向量\n",
    "        \n",
    "        return {'image' : img, 'landmarks' : landmarks}\n",
    "\n",
    "#随机裁剪样本中的图像.\n",
    "#output_size（tuple或int）：所需的输出大小。 如果是int，方形裁剪是\n",
    "class RandomCrop() :\n",
    "    def __init__(self, output_size) :\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int) :\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else :\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "        \n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "        \n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "        \n",
    "        image = image[top: top + new_h, left: left + new_w]\n",
    "        landmarks = landmarks - torch.tensor([left, top])\n",
    "        \n",
    "        return {'image': image, 'landmarks': landmarks}\n",
    "\n",
    "#数据增强\n",
    "class ToTensor() :\n",
    "    def __call__(self, sample) :\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'image' : torch.from_numpy(image), 'landmarks' : landmarks}\n",
    "\n",
    "# scale = Rescale(256)\n",
    "# crop = RandomCrop(128)\n",
    "# composed = transforms.Compose([Rescale(256), RandomCrop(224)])\n",
    "# 在样本上应用上述的每个变换。\n",
    "# fig = plt.figure()\n",
    "# sample = face_dataset[65]\n",
    "\n",
    "# for i, tsfrm in enumerate([scale, crop, composed]):\n",
    "#     transformed_sample = tsfrm(sample)\n",
    "# #     print(transformed_sample['image'].shape)\n",
    "#     ax = plt.subplot(1, 3, i + 1)\n",
    "#     plt.tight_layout()\n",
    "#     ax.set_title(type(tsfrm).__name__)\n",
    "#     show_landmarks(**transformed_sample)\n",
    "# plt.show()\n",
    "\n",
    "transformed_dataset = FaceLandmarksDataSet(csv_file = 'faces/face_landmarks.csv', root_dir = 'faces', transform = transforms.Compose([\n",
    "    Rescale(256),\n",
    "    RandomCrop(244),\n",
    "    ToTensor()\n",
    "]))\n",
    "\n",
    "# for i in range(len(face_dataset)) :\n",
    "#     sample = transformed_dataset[i]\n",
    "#     print(i, sample['image'].size(), sample['landmarks'].size())\n",
    "#     if i == 3 :\n",
    "#         break\n",
    "\n",
    "def show_landmarks_batch(sample_batched) :\n",
    "    images_batch, landmarks_batch = sample_batched['image'], sample_batched['landmarks']\n",
    "    batch_size = len(images_batch)\n",
    "#     print(images_batch.size())\n",
    "    im_size = images_batch.size(2)\n",
    "#     print(im_size)\n",
    "#     print(batch_size)\n",
    "    #grid_border_size = 2\n",
    "    #torchvision.utils.make_grid(tensor, padding = 2, nrow = 8)\n",
    "    #make_grid的作用是将若干幅图像拼成一幅图像。其中padding的作用就是子图像与子图像之间的pad有多宽。\n",
    "    grid = utils.make_grid(images_batch, padding=0)\n",
    "    plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "    for i in range(batch_size):\n",
    "        plt.scatter(landmarks_batch[i, :, 0].numpy() + i * im_size + (i + 1),\n",
    "                landmarks_batch[i, :, 1].numpy(), s = 10, marker = '.', c = 'r')\n",
    "    plt.title('Batch from dataloader')\n",
    "    \n",
    "dataloader = DataLoader(transformed_dataset, batch_size = 4, shuffle = True, num_workers = 0)\n",
    "\n",
    "for i_batched, sample_batched in enumerate(dataloader) :\n",
    "    print(i_batched, sample_batched['image'].size(), sample_batched['landmarks'].size())\n",
    "    if i_batched == 3 :\n",
    "        show_landmarks_batch(sample_batched)\n",
    "        plt.axis('off')\n",
    "        plt.ioff()\n",
    "        plt.show()\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
