{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79ea43b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1,  train_loss : 0.08120395546867842, test_loss : 0.07978569679278895\n",
      "epoch : 2,  train_loss : 0.06483564646299345, test_loss : 0.059301908089764765\n",
      "epoch : 3,  train_loss : 0.05298390530073611, test_loss : 0.043189333419733786\n",
      "epoch : 4,  train_loss : 0.04368476118376708, test_loss : 0.031013802724349237\n",
      "epoch : 5,  train_loss : 0.03661416727841803, test_loss : 0.022225935709168365\n",
      "epoch : 6,  train_loss : 0.03140421077296512, test_loss : 0.016185233162880782\n",
      "epoch : 7,  train_loss : 0.027662565356470842, test_loss : 0.012224399436877935\n",
      "epoch : 8,  train_loss : 0.025011655210566905, test_loss : 0.009728723584227762\n",
      "epoch : 9,  train_loss : 0.023125611297698943, test_loss : 0.008197502219998667\n",
      "epoch : 10,  train_loss : 0.021751287934805755, test_loss : 0.007266210322480424\n",
      "epoch : 11,  train_loss : 0.020709308571589348, test_loss : 0.006693170396720968\n",
      "epoch : 12,  train_loss : 0.019881484660702314, test_loss : 0.006329186023834275\n",
      "epoch : 13,  train_loss : 0.01919390535821949, test_loss : 0.00608676758281298\n",
      "epoch : 14,  train_loss : 0.018601799507444495, test_loss : 0.005916331527948166\n",
      "epoch : 15,  train_loss : 0.01807843221335035, test_loss : 0.005790397129088261\n",
      "epoch : 16,  train_loss : 0.017607737852254845, test_loss : 0.005693866520376818\n",
      "epoch : 17,  train_loss : 0.017179794441419403, test_loss : 0.0056184034476257005\n",
      "epoch : 18,  train_loss : 0.016788172520498128, test_loss : 0.005559282673713207\n",
      "epoch : 19,  train_loss : 0.01642841982731514, test_loss : 0.005513683607701586\n",
      "epoch : 20,  train_loss : 0.01609721744113761, test_loss : 0.005479778272687683\n",
      "epoch : 21,  train_loss : 0.01579191734324286, test_loss : 0.005456263993456664\n",
      "epoch : 22,  train_loss : 0.015510297118136972, test_loss : 0.005442106619691485\n",
      "epoch : 23,  train_loss : 0.015250417982835177, test_loss : 0.005436420346476602\n",
      "epoch : 24,  train_loss : 0.015010549245672336, test_loss : 0.005438421958238272\n",
      "epoch : 25,  train_loss : 0.014789125473807405, test_loss : 0.005447394277899084\n",
      "epoch : 26,  train_loss : 0.014584717771213252, test_loss : 0.0054626678790168776\n",
      "epoch : 27,  train_loss : 0.014396014259028289, test_loss : 0.005483632290539111\n",
      "epoch : 28,  train_loss : 0.014221807918731181, test_loss : 0.005509692194796362\n",
      "epoch : 29,  train_loss : 0.0140609908523875, test_loss : 0.0055403212675981086\n",
      "epoch : 30,  train_loss : 0.013912532876152758, test_loss : 0.005575004869472149\n",
      "epoch : 31,  train_loss : 0.013775488289013127, test_loss : 0.005613266234344624\n",
      "epoch : 32,  train_loss : 0.013648984416724875, test_loss : 0.005654673379858061\n",
      "epoch : 33,  train_loss : 0.013532199284293875, test_loss : 0.00569881099330449\n",
      "epoch : 34,  train_loss : 0.013424382054949403, test_loss : 0.005745294451842839\n",
      "epoch : 35,  train_loss : 0.013324835972521156, test_loss : 0.005793771066513008\n",
      "epoch : 36,  train_loss : 0.013232921383612659, test_loss : 0.005843916249051364\n",
      "epoch : 37,  train_loss : 0.013148031964420196, test_loss : 0.005895407649589017\n",
      "epoch : 38,  train_loss : 0.013069615933955185, test_loss : 0.005947976517598216\n",
      "epoch : 39,  train_loss : 0.012997160611574014, test_loss : 0.006001360202721903\n",
      "epoch : 40,  train_loss : 0.012930191288736778, test_loss : 0.006055331885338976\n",
      "epoch : 41,  train_loss : 0.012868272098793479, test_loss : 0.006109664658094548\n",
      "epoch : 42,  train_loss : 0.012810997578834419, test_loss : 0.006164160027600935\n",
      "epoch : 43,  train_loss : 0.012757992206198695, test_loss : 0.00621864757188116\n",
      "epoch : 44,  train_loss : 0.012708911488288722, test_loss : 0.006272946233649064\n",
      "epoch : 45,  train_loss : 0.012663442746810973, test_loss : 0.006326936755170676\n",
      "epoch : 46,  train_loss : 0.012621290808521509, test_loss : 0.006380478506134996\n",
      "epoch : 47,  train_loss : 0.012582188732994356, test_loss : 0.006433468708491017\n",
      "epoch : 48,  train_loss : 0.012545887595039988, test_loss : 0.006485796260443061\n",
      "epoch : 49,  train_loss : 0.012512161053952872, test_loss : 0.006537386873824781\n",
      "epoch : 50,  train_loss : 0.012480801922201542, test_loss : 0.006588166863563143\n",
      "epoch : 51,  train_loss : 0.01245162115442551, test_loss : 0.006638058231197413\n",
      "epoch : 52,  train_loss : 0.012424443663318525, test_loss : 0.006687004469796229\n",
      "epoch : 53,  train_loss : 0.012399107383538754, test_loss : 0.006734973750655928\n",
      "epoch : 54,  train_loss : 0.012375468337773846, test_loss : 0.006781921292078114\n",
      "epoch : 55,  train_loss : 0.012353387187783317, test_loss : 0.006827818167883569\n",
      "epoch : 56,  train_loss : 0.012332745140840885, test_loss : 0.006872644617581153\n",
      "epoch : 57,  train_loss : 0.012313424664538039, test_loss : 0.006916391209513355\n",
      "epoch : 58,  train_loss : 0.012295328213792636, test_loss : 0.006959036917297342\n",
      "epoch : 59,  train_loss : 0.012278358674513908, test_loss : 0.00700057674607798\n",
      "epoch : 60,  train_loss : 0.012262425368088843, test_loss : 0.00704100688780214\n",
      "--------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "%matplotlib\n",
    "\n",
    "def Boston_DataSet() :\n",
    "    data = np.loadtxt('housing.data')\n",
    "    \n",
    "    train_data = torch.FloatTensor(data[ : 432, : ])    \n",
    "    test_data = torch.FloatTensor(data[432 : , : ])\n",
    "    #训练集\n",
    "    mean = train_data.mean(dim = 0)\n",
    "    max_train, _ = torch.max(train_data, dim = 0)\n",
    "    min_train, _ = torch.min(train_data, dim = 0)\n",
    "    \n",
    "    train_data = (train_data - mean) / (max_train - min_train)\n",
    "\n",
    "    test_data = (test_data - mean) / (max_train - min_train)\n",
    "    \n",
    "    return train_data, test_data\n",
    "class MyModel(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super(MyModel, self).__init__() \n",
    "        self.Net = nn.Sequential( \n",
    "#                                 nn.ReLU(), \n",
    "#                                 nn.Linear(6, 4), \n",
    "#                                 nn.ReLU(),\n",
    "                                nn.Linear(13, 1))\n",
    "    def forward(self, input) :\n",
    "        return self.Net(input)\n",
    "        \n",
    "train_data, test_data = Boston_DataSet()\n",
    "train_data, train_target, test_data, test_target = train_data[ : , : 13], train_data[ : , 13], test_data[ : , : 13], test_data[ : , 13]\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MyModel().to(device)\n",
    "\n",
    "learning_rate = 0.0001\n",
    "max_epoch = 60\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr = learning_rate)\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(max_epoch) :\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for input, label in zip(train_data, train_target) :\n",
    "        input, label = input.to(device), label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(input)\n",
    "    \n",
    "        loss = criterion(output, label)\n",
    "        train_loss += loss.sum().item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_losses.append(train_loss / len(train_data))\n",
    "    \n",
    "    with torch.no_grad() :\n",
    "        pred = []#模型预测的房价\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        for input, label in zip(test_data, test_target) :\n",
    "            input, label = input.to(device), label.to(device)#用训练集的均值和标准差对测试集进行标准化\n",
    "            out = model(input)\n",
    "            loss = criterion(out, label)\n",
    "            test_loss += loss.item()\n",
    "            pred.extend(out)\n",
    "\n",
    "        test_losses.append(test_loss / len(test_data))\n",
    "\n",
    "    print(f'epoch : {epoch + 1},  train_loss : {train_loss / len(train_data)}, ' \n",
    "          f'test_loss : {test_loss / len(test_data)}')\n",
    "\n",
    "# print(pred, test_target)\n",
    "plt.figure()\n",
    "plt.subplot(1, 2, 1), plt.plot(list(range(len(test_target))), test_target, pred), plt.legend(['True price', 'My pred'])\n",
    "plt.subplot(1, 2, 2), plt.plot(list(range(max_epoch)), train_losses, test_losses), plt.legend(['train_losses', 'test_losses'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('--------------------------------------------------------------------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
