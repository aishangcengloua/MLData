{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccdb16bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n",
      "PassengerId    891\n",
      "Survived       891\n",
      "Pclass         891\n",
      "Name           891\n",
      "Sex            891\n",
      "Age            714\n",
      "SibSp          891\n",
      "Parch          891\n",
      "Ticket         891\n",
      "Fare           891\n",
      "Cabin          204\n",
      "Embarked       889\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n",
      "       PassengerId    Survived      Pclass         Age       SibSp       Parch        Fare\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.str_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-b61dc3ab8a69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m \u001b[0mtrain_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTitanicSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[0mval_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTitanicSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'val'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTitanicSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-b61dc3ab8a69>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, model)\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;32melse\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.str_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "df1 = pd.read_csv('train.csv')\n",
    "print(df1.shape)\n",
    "print(df1.count())\n",
    "print(df1.info())\n",
    "print(df1.describe())\n",
    "class TitanicSet(Dataset) :\n",
    "    def __init__(self, path, model = 'train') :\n",
    "        super(TitanicSet, self).__init__()\n",
    "        self.model = model\n",
    "        with open(path, 'r') as file :\n",
    "            data = list(csv.reader(file))\n",
    "            data = np.array(data[1 : ])\n",
    "        if model == 'test' :\n",
    "            return torch.tensor(self.data[ : , 1 : ])\n",
    "        else :\n",
    "            target = data[ : , 1]\n",
    "            data = data[ : , 2 : ]\n",
    "            train_index = []\n",
    "            val_index = []\n",
    "            for i in range(data.shape[0]) :\n",
    "                if i % 10 == 0 :\n",
    "                    val_index.append(i)\n",
    "                else :\n",
    "                    train_index.append(i)\n",
    "            if model == 'val' :\n",
    "                self.data = torch.tensor(data[train_index, : ])\n",
    "                self.target = torch.LongTensor(target[train_index])\n",
    "            else :\n",
    "                self.data = torch.tensor(data[val_index, : ])\n",
    "                self.target = torch.LongTensor(target[val_index])\n",
    "        def __getitem__(self, item) :\n",
    "            if self.model == 'test' :\n",
    "                return self.data[item]\n",
    "            else :\n",
    "                return self.data[item], self.target[item]\n",
    "        def __len__(self) :\n",
    "            return len(self.data)\n",
    "class MyModel(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super(MyModel, self).__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(891, 512),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(512, 256),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(256, 128),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(128, 64),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(64, 2))\n",
    "    def forward(self, input) :\n",
    "        return self.net(input)\n",
    "\n",
    "train_set = TitanicSet('train.csv', model = 'train')\n",
    "val_set = TitanicSet('train.csv', model = 'val')\n",
    "test_set = TitanicSet('test.csv', model = 'test')\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "test_loader = DataLoader(test_set, batch_size = batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "model = MyModel().cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "max_epoch = 1000\n",
    "\n",
    "for i in range(max_epoch) :\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    val_losses = []\n",
    "    train_losses = []\n",
    "    min_mse = 1000\n",
    "    model.train()\n",
    "    for x, label in train_loader :\n",
    "        x, label = x.cuda(), label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = criterion(output, label)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, pred = torch.max(output, 1)\n",
    "        num_correct = (pred == label).sum().item()\n",
    "        acc = num_correct / x.shape[0]\n",
    "        train_acc += acc\n",
    "    total_loss = []\n",
    "    with torch.no_grad() :\n",
    "        model.eval()\n",
    "        for x, label in val_loader :\n",
    "            output = model(x)\n",
    "            loss = criterion(output, label)\n",
    "            total_loss.append(loss.item())\n",
    "        val_loss = sum(total_loss) / len(total_loss)\n",
    "    if val_loss < min_mse :\n",
    "        min_mse = val_loss\n",
    "        torch.save(model.state_dicta(), 'mymodel.pth')\n",
    "    print('epoch : {:02d}, train_loss : {}, train_acc : {}'.format(epoch + 1, \n",
    "                                                               train_loss / len(train_loader), \n",
    "                                                               train_acc  / len(train_loader)))\n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "    val_acces.append(train_acc  / len(train_loader))\n",
    "\n",
    "del model\n",
    "bestmodel = MyModel().cuda()\n",
    "ckpt = torch.load('mymodel.pth', map_location= \"cpu\")\n",
    "bestmodel.load_state_dict(ckpt)\n",
    "\n",
    "with torch.no_grad() :\n",
    "    output = []\n",
    "    bestmodel.eval()\n",
    "    for x in test_loader :\n",
    "        x = x.cuda()\n",
    "        out = bestmodel(x)\n",
    "        _, pred = torch.max(out, 1)\n",
    "        for i in pred.cpu().numpy() :\n",
    "            output.append(i)\n",
    "\n",
    "with open('predictions.csv', 'w') as file :\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['PassengerId', 'Survived'])\n",
    "    for id, label in enumerate(output) :\n",
    "        writer.writerow([id + 892, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32a25bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
