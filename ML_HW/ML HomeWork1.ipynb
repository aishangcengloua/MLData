{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62382f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save model epoch =    2, loss = 51.0681\n",
      "Save model epoch =    3, loss = 12.6505\n",
      "Save model epoch =    4, loss = 5.6752\n",
      "Save model epoch =    5, loss = 4.0360\n",
      "Save model epoch =    6, loss = 3.3920\n",
      "Save model epoch =    7, loss = 2.8617\n",
      "Save model epoch =    8, loss = 2.4789\n",
      "Save model epoch =    9, loss = 2.2375\n",
      "Save model epoch =   10, loss = 2.0216\n",
      "Save model epoch =   11, loss = 1.8489\n",
      "Save model epoch =   12, loss = 1.7353\n",
      "Save model epoch =   13, loss = 1.5770\n",
      "Save model epoch =   14, loss = 1.5064\n",
      "Save model epoch =   15, loss = 1.4060\n",
      "Save model epoch =   16, loss = 1.3681\n",
      "Save model epoch =   17, loss = 1.3126\n",
      "Save model epoch =   18, loss = 1.2665\n",
      "Save model epoch =   19, loss = 1.2314\n",
      "Save model epoch =   20, loss = 1.1806\n",
      "Save model epoch =   22, loss = 1.1721\n",
      "Save model epoch =   26, loss = 1.1052\n",
      "Save model epoch =   27, loss = 1.0713\n",
      "Save model epoch =   30, loss = 1.0334\n",
      "Save model epoch =   31, loss = 1.0146\n",
      "Save model epoch =   34, loss = 1.0106\n",
      "Save model epoch =   37, loss = 1.0025\n",
      "Save model epoch =   38, loss = 0.9877\n",
      "Save model epoch =   40, loss = 0.9654\n",
      "Save model epoch =   42, loss = 0.9639\n",
      "Save model epoch =   45, loss = 0.9574\n",
      "Save model epoch =   47, loss = 0.9543\n",
      "Save model epoch =   48, loss = 0.9490\n",
      "Save model epoch =   49, loss = 0.9289\n",
      "Save model epoch =   50, loss = 0.9289\n",
      "Save model epoch =   54, loss = 0.8931\n",
      "Save model epoch =   57, loss = 0.8862\n",
      "Save model epoch =   65, loss = 0.8727\n",
      "Save model epoch =   66, loss = 0.8583\n",
      "Save model epoch =   75, loss = 0.8431\n",
      "Save model epoch =   80, loss = 0.8295\n",
      "Save model epoch =  113, loss = 0.8216\n",
      "Save model epoch =  122, loss = 0.8074\n",
      "Save model epoch =  138, loss = 0.8072\n",
      "Save model epoch =  151, loss = 0.7916\n",
      "Save model epoch =  173, loss = 0.7882\n",
      "Save model epoch =  199, loss = 0.7803\n",
      "Save model epoch =  262, loss = 0.7790\n",
      "Save model epoch =  269, loss = 0.7764\n",
      "Save model epoch =  303, loss = 0.7702\n",
      "Save model epoch =  330, loss = 0.7667\n",
      "Save model epoch =  340, loss = 0.7640\n",
      "Save model epoch =  381, loss = 0.7631\n",
      "Save model epoch =  386, loss = 0.7609\n",
      "Save model epoch =  403, loss = 0.7581\n",
      "Save model epoch =  407, loss = 0.7506\n",
      "Save model epoch =  419, loss = 0.7471\n",
      "Save model epoch =  427, loss = 0.7425\n",
      "Save model epoch =  446, loss = 0.7351\n",
      "Save model epoch =  465, loss = 0.7321\n",
      "Save model epoch =  468, loss = 0.7281\n",
      "Save model epoch =  471, loss = 0.7270\n",
      "Save model epoch =  480, loss = 0.7252\n",
      "Save model epoch =  508, loss = 0.7218\n",
      "Save model epoch =  541, loss = 0.7204\n",
      "Save model epoch =  572, loss = 0.7118\n",
      "Save model epoch =  615, loss = 0.6994\n",
      "Save model epoch =  657, loss = 0.6951\n",
      "Save model epoch =  684, loss = 0.6906\n",
      "Save model epoch =  796, loss = 0.6873\n",
      "Save model epoch =  801, loss = 0.6839\n",
      "Save model epoch =  847, loss = 0.6807\n",
      "Save model epoch =  893, loss = 0.6763\n",
      "Save model epoch =  912, loss = 0.6729\n",
      "Save model epoch =  975, loss = 0.6686\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "seed = 42069\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "class Covid19Sets(Dataset):\n",
    "    def __init__(self, path, model = 'train'):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        with open(path) as file :\n",
    "            data_csv = list(csv.reader(file))\n",
    "            data = np.array(data_csv[1 : ])[ : , 1 :].astype(float)\n",
    "        if model == 'test' :\n",
    "            data = data[ : , 0 : 93]\n",
    "            self.data = torch.FloatTensor(data)\n",
    "        else :\n",
    "            target = data[ : , -1]\n",
    "            data = data[:, 0 : 93]\n",
    "            train_index = []\n",
    "            dev_index = []\n",
    "            for i in range(data.shape[0]) :\n",
    "                if i % 10 == 0 :\n",
    "                    dev_index.append(i)\n",
    "                else :\n",
    "                    train_index.append(i)\n",
    "            if model == 'train' :\n",
    "                self.target = torch.FloatTensor(target[train_index])\n",
    "                self.data = torch.FloatTensor(data[train_index,  0 : 93])\n",
    "            else :\n",
    "                self.target = torch.FloatTensor(target[dev_index])\n",
    "                self.data = torch.FloatTensor(data[dev_index, 0 : 93])\n",
    "        self.data[: , 40 : ] = (self.data[:, 40 :] - self.data[:, 40 : ].mean(dim = 0)) / self.data[: , 40 :].std(dim = 0)\n",
    "        self.dim = self.data.shape[1]\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        if self.model == 'train' or self.model == 'dev' :\n",
    "            return self.data[item], self.target[item]\n",
    "        else :\n",
    "            return self.data[item]\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "def prep_dataloader(path, model, batch_size, num_works = 0) :\n",
    "    dataset = Covid19Sets(path, model)\n",
    "    dataLoaderset = DataLoader(dataset,\n",
    "                               batch_size,\n",
    "                               shuffle=(model == 'train'),\n",
    "                               drop_last=False,\n",
    "                               num_workers=num_works,\n",
    "                               pin_memory=False)\n",
    "    #print(model)\n",
    "    return dataLoaderset\n",
    "\n",
    "def prep_dataloader(path, model, batch_size, num_works = 0) :\n",
    "    dataset = Covid19Sets(path, model)\n",
    "    dataLoaderset = DataLoader(dataset,\n",
    "                               batch_size,\n",
    "                               shuffle=(model == 'train'),\n",
    "                               drop_last=False,\n",
    "                               num_workers=num_works,\n",
    "                               pin_memory=False)\n",
    "    #print(model)\n",
    "    return dataLoaderset\n",
    "\n",
    "class Mymodel(nn.Module) :\n",
    "    def __init__(self, input_dim):\n",
    "        super(Mymodel, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 1)\n",
    "        )\n",
    "        self.critertion = nn.MSELoss(reduction='mean')\n",
    "    def forward(self, input):\n",
    "        return self.net(input).squeeze(1)\n",
    "    def cal_loss(self, pred, target):\n",
    "        return self.critertion(pred, target)\n",
    "\n",
    "def train(model, train_data, dev_data) :\n",
    "    max_epoch = 1000\n",
    "    epoch = 1\n",
    "    optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum=0.9)\n",
    "    train_loss = []\n",
    "    dev_loss = []\n",
    "    min_mse = 1000\n",
    "    break_flag = 0\n",
    "    while epoch < max_epoch :\n",
    "        model.train()\n",
    "        for input, label in train_data :\n",
    "            optimizer.zero_grad()\n",
    "            output = model(input)\n",
    "            loss = model.cal_loss(output, label)\n",
    "            train_loss.append(loss.detach())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        dev_mse = dev(model, dev_data)\n",
    "        if dev_mse < min_mse :\n",
    "            min_mse = dev_mse\n",
    "            print('Save model epoch = {:4d}, loss = {:.4f}'.format(epoch + 1, min_mse))\n",
    "            torch.save(model.state_dict(), 'my_models/mymodel.pth')\n",
    "            break_flag = 0\n",
    "        else :\n",
    "            break_flag += 1\n",
    "        dev_loss.append(dev_mse.detach())\n",
    "        if break_flag > 200 :\n",
    "            break\n",
    "        epoch += 1\n",
    "    return train_loss, dev_loss\n",
    "def dev(model, dev_data) :\n",
    "    model.eval()\n",
    "    total_loss = []\n",
    "    for input, label in dev_data :\n",
    "        output = model(input)\n",
    "        total_loss.append(model.cal_loss(output, label))\n",
    "    return sum(total_loss) / len(total_loss)\n",
    "\n",
    "def test(model,test_data) :\n",
    "    model.eval()\n",
    "    output = []\n",
    "    for input in test_data :\n",
    "        pred = model(input)\n",
    "        output.append(pred.detach())\n",
    "    output = torch.cat(output, dim = 0).numpy()\n",
    "    return output\n",
    "\n",
    "\n",
    "# 绘制学习曲线\n",
    "def plot_learning_curve(train_loss, dev_loss, title=''):\n",
    "    total_steps = len(train_loss)\n",
    "    x_1 = range(total_steps)\n",
    "    x_2 = x_1[::len(train_loss) // len(dev_loss)]\n",
    "    plt.figure(1, figsize=(6, 4))\n",
    "    plt.plot(x_1, train_loss, c='tab:red', label='train')\n",
    "    plt.plot(x_2, dev_loss, c='tab:cyan', label='dev')\n",
    "    plt.ylim(0.0, 5.)\n",
    "    plt.xlabel('Training steps')\n",
    "    plt.ylabel('MSE loss')\n",
    "    plt.title('Learning curve of {}'.format(title))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_pred(dv_set, model, device, lim=35., preds=None, targets=None):\n",
    "    if preds is None or targets is None:\n",
    "        model.eval()\n",
    "        preds, targets = [], []\n",
    "        for x, y in dv_set:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            with torch.no_grad():\n",
    "                pred = model(x)\n",
    "                preds.append(pred.detach().cpu())\n",
    "                targets.append(y.detach().cpu())\n",
    "        preds = torch.cat(preds, dim=0).numpy()\n",
    "        targets = torch.cat(targets, dim=0).numpy()\n",
    "    plt.figure(2, figsize=(5, 5))\n",
    "    plt.scatter(targets, preds, c='r', alpha=0.5)\n",
    "    plt.plot([-0.2, lim], [-0.2, lim], c='b')\n",
    "    plt.xlim(-0.2, lim)\n",
    "    plt.ylim(-0.2, lim)\n",
    "    plt.xlabel('ground truth value')\n",
    "    plt.ylabel('predicted value')\n",
    "    plt.title('Ground Truth v.s. Prediction')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def save_pred(preds, file):\n",
    "    print('Saving results to {}'.format(file))\n",
    "    with open(file, 'w') as fp:\n",
    "        writer = csv.writer(fp)\n",
    "        writer.writerow(['id', 'tested_positive'])\n",
    "        for i, p in enumerate(preds):  # enumerate() 函数用于将一个可遍历的数据对象组合为一个索引序列，同时列出数据和数据下标\n",
    "            writer.writerow([i, p])\n",
    "\n",
    "\n",
    "os.makedirs('my_models', exist_ok=True)\n",
    "\n",
    "# 加载数据\n",
    "train_data = prep_dataloader('covid.train.csv', 'train', batch_size=135)\n",
    "dev_data = prep_dataloader('covid.train.csv', 'dev', batch_size=135)\n",
    "test_data = prep_dataloader('covid.test.csv', 'test', batch_size=135)\n",
    "\n",
    "mymodel = Mymodel(train_data.dataset.dim)\n",
    "train_loss, dev_loss = train(mymodel, train_data, dev_data)\n",
    "plot_learning_curve(train_loss, dev_loss, title='deep model')\n",
    "del mymodel\n",
    "\n",
    "model = Mymodel(train_data.dataset.dim)\n",
    "ckpt = torch.load('my_models/mymodel.pth', map_location='cpu')  # 加载最好的模型\n",
    "model.load_state_dict(ckpt)\n",
    "plot_pred(dev_data, model, 'cpu')\n",
    "preds = test(model, test_data)\n",
    "\n",
    "save_pred(preds, 'mypred.csv')\n",
    "print('all done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9f5ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6947ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
