{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af6839d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001/003] Train Acc: 0.575048 Loss: 1.403044 | Val Acc: 0.665181 loss: 1.069692\n",
      "[002/003] Train Acc: 0.686195 Loss: 0.985308 | Val Acc: 0.688143 loss: 0.975280\n",
      "[003/003] Train Acc: 0.715884 Loss: 0.878557 | Val Acc: 0.697087 loss: 0.943670\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import gc\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "#os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "Data_train = np.load('timit_11/train_11.npy')\n",
    "Data_train_label = np.load('timit_11/train_label_11.npy')\n",
    "Data_test = np.load('timit_11/test_11.npy')\n",
    "\n",
    "class TIMITData(Dataset) :\n",
    "    def __init__(self, X, y = None) :\n",
    "        self.data = torch.from_numpy(X).float()\n",
    "        if y is not None :\n",
    "            y = y.astype(np.int32)\n",
    "            self.label = torch.LongTensor(y)\n",
    "        else:\n",
    "            self.label = None\n",
    "    def __getitem__(self, item) :\n",
    "        if self.label is not None :\n",
    "            return self.data[item], self.label[item]\n",
    "        else:\n",
    "            return self.data[item]\n",
    "    def __len__(self) :\n",
    "        return len(self.data)\n",
    "VAL_RATE = 0.2\n",
    "percent = int(Data_train.shape[0] * (1 - VAL_RATE))\n",
    "train_x, train_y, val_x, val_y = Data_train[ : percent], Data_train_label[ : percent], Data_train[percent :], Data_train_label[percent :]\n",
    "\n",
    "Batch_size = 270\n",
    "train_data = TIMITData(train_x, train_y)\n",
    "val_data = TIMITData(val_x, val_y)\n",
    "train_loader = DataLoader(train_data, batch_size=Batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=Batch_size, shuffle=False)\n",
    "\n",
    "del Data_train, Data_train_label, train_x, train_y, val_x, val_y\n",
    "gc.collect()\n",
    "\n",
    "class Classifier(nn.Module) :\n",
    "    def __init__(self) :\n",
    "        super(Classifier, self).__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(429, 1024),\n",
    "                                nn.Sigmoid(),\n",
    "                                nn.Linear(1024, 512),\n",
    "                                nn.Sigmoid(),\n",
    "                                nn.Linear(512, 128),\n",
    "                                nn.Sigmoid(),\n",
    "                                nn.Linear(128, 39))\n",
    "    def forward(self, x) :\n",
    "        return self.net(x)\n",
    "def get_device() :\n",
    "    return 'cuda'if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "device = get_device()\n",
    "Learning_rate = 0.001\n",
    "max_epoch = 20\n",
    "model = Classifier().to(device)\n",
    "critertion = nn.CrossEntropyLoss()\n",
    "optimization = optim.Adam(model.parameters(), lr=Learning_rate)\n",
    "model_path = './model.ckpt'\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(max_epoch) :\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    model.train()\n",
    "    for x, label in train_loader:\n",
    "        x = x.to(device)\n",
    "        label = label.to(device)\n",
    "        optimization.zero_grad()\n",
    "        output = model(x)\n",
    "        #print(output.shape)\n",
    "        #print(label.shape)\n",
    "        loss = critertion(output, label)\n",
    "        _, train_pred = torch.max(output, 1)\n",
    "        loss.backward()\n",
    "        optimization.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        num_correct = (train_pred.cpu() == label.cpu()).sum().item()\n",
    "        train_acc += num_correct / x.shape[0]\n",
    "        \n",
    "    if len(val_data) > 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad() :\n",
    "            for x, label in val_loader :\n",
    "                x = x.to(device) \n",
    "                label = label.to(device)\n",
    "                output = model(x)\n",
    "                loss = critertion(output, label)\n",
    "                _, val_pred = torch.max(output, 1)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                num_correct = (val_pred.cpu() == label.cpu()).sum().item()\n",
    "                val_acc += num_correct / x.shape[0]\n",
    "            print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f} | Val Acc: {:3.6f} loss: {:3.6f}'.format(epoch + 1, max_epoch, \n",
    "                                                                                                                train_acc / len(train_loader), train_loss / len(train_loader), \n",
    "                                                                                                                 val_acc / len(val_loader), val_loss / len(val_loader)))\n",
    "            if val_acc > best_acc :\n",
    "                best_acc = val_acc\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "    else:\n",
    "        print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f}'.format(\n",
    "            epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader)\n",
    "        ))\n",
    "if len(val_data) == 0 :\n",
    "      torch.save(model.state_dict(), model_path)\n",
    "\n",
    "test_data = TIMITData(Data_test, y = None)\n",
    "test_loader = DataLoader(test_data, batch_size = Batch_size, shuffle=False)\n",
    "predict = []\n",
    "model = Classifier().to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad() :\n",
    "    for x in test_loader :\n",
    "        x = x.to(device)\n",
    "        output = model(x)\n",
    "        _, test_pred = torch.max(output, 1)\n",
    "    \n",
    "        for i in test_pred.cpu().numpy() :\n",
    "            predict.append(i)\n",
    "with open('prediction.csv', 'w') as file :\n",
    "    file.write('Id,Class\\n')\n",
    "    for i, Class in enumerate(predict) :\n",
    "        file.write('{},{}\\n'.format(i, Class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1faefb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
